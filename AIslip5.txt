import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet

# Download required NLTK packages (Run once)
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')

# Initialize Lemmatizer
lemmatizer = WordNetLemmatizer()

# Sample text
text = "The cats are running faster than the other animals. They studies daily."

# Tokenize sentence into words
words = nltk.word_tokenize(text)

print("\nOriginal Words → Lemmatized Words")
print("---------------------------------\n")

for word in words:
    print(word, " → ", lemmatizer.lemmatize(word))
---------------------------------------------------------------------------
from collections import deque

# Graph represented as adjacency list
graph = {
    1: [2, 4],
    2: [3],
    3: [4, 5, 6],
    4: [],
    5: [7, 8],
    6: [8],
    7: [8],
    8: []
}

def bfs(start, goal):
    visited = set()
    queue = deque([[start]])  # queue stores paths

    while queue:
        path = queue.popleft()
        node = path[-1]  # last node in path

        if node == goal:          # Goal found
            return path

        if node not in visited:
            visited.add(node)
            for neighbour in graph[node]:
                new_path = list(path)
                new_path.append(neighbour)
                queue.append(new_path)

    return None


# Run BFS
start = 1
goal = 8
result = bfs(start, goal)

print("BFS Traversal Path from", start, "to", goal, ": ", result)
